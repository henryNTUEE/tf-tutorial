{
    "cells": [
        {
            "cell_type": "code", 
            "source": "!git clone https://github.com/henryNTUEE/tf-tutorial.git", 
            "metadata": {}, 
            "outputs": [
                {
                    "output_type": "stream", 
                    "text": "Cloning into 'tf-tutorial'...\nremote: Counting objects: 80, done.\u001b[K\nremote: Compressing objects: 100% (51/51), done.\u001b[K\nremote: Total 80 (delta 16), reused 76 (delta 14), pack-reused 0\u001b[K\nUnpacking objects: 100% (80/80), done.\n", 
                    "name": "stdout"
                }
            ], 
            "execution_count": 19
        }, 
        {
            "cell_type": "code", 
            "source": "%cd tf-tutorial/tensorflow_lyrics_bot/", 
            "metadata": {}, 
            "outputs": [
                {
                    "output_type": "stream", 
                    "text": "/gpfs/global_fs01/sym_shared/YPProdSpark/user/s940-fbcc213783342d-a0c48b40f6b0/notebook/work/tf-tutorial/tensorflow_lyrics_bot\n", 
                    "name": "stdout"
                }
            ], 
            "execution_count": 20
        }, 
        {
            "cell_type": "code", 
            "source": "# The code was removed by DSX for sharing.", 
            "metadata": {}, 
            "outputs": [], 
            "execution_count": 21
        }, 
        {
            "cell_type": "code", 
            "source": "print (data.getvalue().split('\\n')[0])", 
            "metadata": {}, 
            "outputs": [
                {
                    "output_type": "stream", 
                    "text": "\u4e0b\u8ab2 \u82b1\u8def \u7c73   \u7b2c\u4e00 \u96c6   \u63a2\u7d22 \u87cb\u87c0 \u4e4b\u65c5\n", 
                    "name": "stdout"
                }
            ], 
            "execution_count": 22
        }, 
        {
            "cell_type": "code", 
            "source": "with open('works/subtitle/data/train/chat.txt','w') as w:\n    for line in data:\n        w.write(line + '\\n')", 
            "metadata": {
                "collapsed": true
            }, 
            "outputs": [], 
            "execution_count": 23
        }, 
        {
            "cell_type": "code", 
            "source": "%cd works/subtitle/data/train/", 
            "metadata": {}, 
            "outputs": [
                {
                    "output_type": "stream", 
                    "text": "/gpfs/global_fs01/sym_shared/YPProdSpark/user/s940-fbcc213783342d-a0c48b40f6b0/notebook/work/tf-tutorial/tensorflow_lyrics_bot/works/subtitle/data/train\n", 
                    "name": "stdout"
                }
            ], 
            "execution_count": 24
        }, 
        {
            "cell_type": "code", 
            "source": "!gzip chat.txt", 
            "metadata": {}, 
            "outputs": [], 
            "execution_count": 27
        }, 
        {
            "cell_type": "code", 
            "source": "%cd ../../../../", 
            "metadata": {}, 
            "outputs": [
                {
                    "output_type": "stream", 
                    "text": "/gpfs/global_fs01/sym_shared/YPProdSpark/user/s940-fbcc213783342d-a0c48b40f6b0/notebook/work/tf-tutorial/tensorflow_lyrics_bot/works\n", 
                    "name": "stdout"
                }
            ], 
            "execution_count": 28
        }, 
        {
            "cell_type": "code", 
            "source": "# %load main.py\nimport os, sys, argparse\n\nsys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))\n\nimport tensorflow as tf\n\nfrom lib.config import params_setup\nfrom lib.train import train\nfrom lib.predict import predict\nfrom lib.chat import chat\n# from lib.mert import mert\n\n\ndef main(_):\n    args = params_setup()\n    print(\"[args]: \", args)\n    if args.mode == 'train':\n      train(args)\n    elif args.mode == 'test':\n      predict(args)\n    elif args.mode == 'chat':\n      chat(args)\n    # elif args.mode == 'mert':\n    #   mert(args)\n\n\nif __name__ == \"__main__\":\n    tf.app.run()", 
            "metadata": {
                "collapsed": true
            }, 
            "outputs": [], 
            "execution_count": null
        }, 
        {
            "cell_type": "code", 
            "source": "# %load lib/train.py\nimport sys, os, math, time, argparse, shutil, gzip\nimport numpy as np\nimport tensorflow as tf\n\nsys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))\n\nfrom six.moves import xrange  # pylint: disable=redefined-builtin\nfrom datetime import datetime\nfrom lib import seq2seq_model_utils, data_utils\n\n\ndef setup_workpath(workspace):\n  for p in ['data', 'nn_models', 'results']:\n    wp = \"%s/%s\" % (workspace, p)\n    if not os.path.exists(wp): os.mkdir(wp)\n\n  data_dir = \"%s/data\" % (workspace)\n  # training data\n  if not os.path.exists(\"%s/chat.in\" % data_dir):\n    n = 0\n    f_zip   = gzip.open(\"%s/train/chat.txt.gz\" % data_dir, 'rt')\n    f_train = open(\"%s/chat.in\" % data_dir, 'w')\n    f_dev   = open(\"%s/chat_test.in\" % data_dir, 'w')\n    for line in f_zip:\n      f_train.write(line)\n      if n < 10000: \n        f_dev.write(line)\n        n += 1\n\n\ndef train(args):\n    print(\"[%s] Preparing dialog data in %s\" % (args.model_name, args.data_dir))\n    setup_workpath(workspace=args.workspace)\n    train_data, dev_data, _ = data_utils.prepare_dialog_data(args.data_dir, args.vocab_size)\n\n    if args.reinforce_learn:\n      args.batch_size = 1  # We decode one sentence at a time.\n\n    gpu_options = tf.GPUOptions(per_process_gpu_memory_fraction=args.gpu_usage)\n    with tf.Session(config=tf.ConfigProto(gpu_options=gpu_options)) as sess:\n\n        # Create model.\n        print(\"Creating %d layers of %d units.\" % (args.num_layers, args.size))\n        model = seq2seq_model_utils.create_model(sess, args, forward_only=False)\n\n        # Read data into buckets and compute their sizes.\n        print(\"Reading development and training data (limit: %d).\" % args.max_train_data_size)\n        dev_set = data_utils.read_data(dev_data, args.buckets, reversed=args.rev_model)\n        train_set = data_utils.read_data(train_data, args.buckets, args.max_train_data_size, reversed=args.rev_model)\n        train_bucket_sizes = [len(train_set[b]) for b in xrange(len(args.buckets))]\n        train_total_size = float(sum(train_bucket_sizes))\n\n        # A bucket scale is a list of increasing numbers from 0 to 1 that we'll use\n        # to select a bucket. Length of [scale[i], scale[i+1]] is proportional to\n        # the size if i-th training bucket, as used later.\n        train_buckets_scale = [sum(train_bucket_sizes[:i + 1]) / train_total_size\n                               for i in xrange(len(train_bucket_sizes))]\n\n        # This is the training loop.\n        step_time, loss = 0.0, 0.0\n        current_step = 0\n        previous_losses = []\n\n        # Load vocabularies.\n        vocab_path = os.path.join(args.data_dir, \"vocab%d.in\" % args.vocab_size)\n        vocab, rev_vocab = data_utils.initialize_vocabulary(vocab_path)\n\n        while True:\n          # Choose a bucket according to data distribution. We pick a random number\n          # in [0, 1] and use the corresponding interval in train_buckets_scale.\n          random_number_01 = np.random.random_sample()\n          bucket_id = min([i for i in xrange(len(train_buckets_scale))\n                           if train_buckets_scale[i] > random_number_01])\n\n          # Get a batch and make a step.\n          start_time = time.time()\n          encoder_inputs, decoder_inputs, target_weights = model.get_batch(\n              train_set, bucket_id)\n\n          # print(\"[shape]\", np.shape(encoder_inputs), np.shape(decoder_inputs), np.shape(target_weights))\n          if args.reinforce_learn:\n            _, step_loss, _ = model.step_rf(args, sess, encoder_inputs, decoder_inputs,\n                                         target_weights, bucket_id, rev_vocab=rev_vocab)\n          else:\n            _, step_loss, _ = model.step(sess, encoder_inputs, decoder_inputs,\n                                         target_weights, bucket_id, forward_only=False, force_dec_input=True)\n\n          step_time += (time.time() - start_time) / args.steps_per_checkpoint\n          loss += step_loss / args.steps_per_checkpoint\n          current_step += 1\n\n          # Once in a while, we save checkpoint, print statistics, and run evals.\n          if (current_step % args.steps_per_checkpoint == 0) and (not args.reinforce_learn):\n            # Print statistics for the previous epoch.\n            perplexity = math.exp(loss) if loss < 300 else float('inf')\n            print (\"global step %d learning rate %.4f step-time %.2f perplexity %.2f @ %s\" %\n                   (model.global_step.eval(), model.learning_rate.eval(), step_time, perplexity, datetime.now()))\n\n            # Decrease learning rate if no improvement was seen over last 3 times.\n            if len(previous_losses) > 2 and loss > max(previous_losses[-3:]):\n              sess.run(model.learning_rate_decay_op)\n\n            previous_losses.append(loss)\n\n            # # Save checkpoint and zero timer and loss.\n            checkpoint_path = os.path.join(args.model_dir, \"model.ckpt\")\n            model.saver.save(sess, checkpoint_path, global_step=model.global_step)\n            step_time, loss = 0.0, 0.0\n\n            # Run evals on development set and print their perplexity.\n            for bucket_id in xrange(len(args.buckets)):\n              encoder_inputs, decoder_inputs, target_weights = model.get_batch(dev_set, bucket_id)\n              _, eval_loss, _ = model.step(sess, encoder_inputs, decoder_inputs, \n                                          target_weights, bucket_id, forward_only=True, force_dec_input=False)\n\n              eval_ppx = math.exp(eval_loss) if eval_loss < 300 else float('inf')\n              print(\"  eval: bucket %d perplexity %.2f\" % (bucket_id, eval_ppx))\n\n            sys.stdout.flush()\n", 
            "metadata": {
                "collapsed": true
            }, 
            "outputs": [], 
            "execution_count": null
        }, 
        {
            "cell_type": "code", 
            "source": "%run main.py --mode train --model subtitle", 
            "metadata": {}, 
            "outputs": [
                {
                    "output_type": "stream", 
                    "text": "[args]:  Namespace(antilm=0, batch_size=64, beam_size=1, buckets=[(5, 10), (10, 15), (20, 25)], data_dir='works/subtitle/data', en_tfboard=0, gpu_usage=1.0, learning_rate=0.5, learning_rate_decay_factor=0.99, max_gradient_norm=5.0, max_train_data_size=0, mert_dataset_path='works/subtitle/data/test/mert_set.txt', mode='train', model_dir='works/subtitle/nn_models', model_name='subtitle', n_bonus=0, num_layers=4, reinforce_learn=0, results_dir='works/subtitle/results', rev_model=0, scope_name='subtitle', size=256, steps_per_checkpoint=500, test_dataset_path='works/subtitle/data/test/test_set.txt', tf_board_dir='works/subtitle/tf_board', vocab_size=150000, work_root='works', workspace='works/subtitle')\n[subtitle] Preparing dialog data in works/subtitle/data\nCreating vocabulary works/subtitle/data/vocab150000.in from data works/subtitle/data/chat.in\nTokenizing data in works/subtitle/data/chat.in\nTokenizing data in works/subtitle/data/chat_test.in\nCreating 4 layers of 256 units.\nCreated model with fresh parameters.\nReading development and training data (limit: 0).\nglobal step 500 learning rate 0.5000 step-time 0.23 perplexity 1.07 @ 2017-10-19 06:58:44.092099\n  eval: bucket 0 perplexity 1.00\n  eval: bucket 1 perplexity 1.00\n  eval: bucket 2 perplexity 1.00\n", 
                    "name": "stdout"
                }, 
                {
                    "traceback": [
                        "\u001b[1;31m\u001b[0m", 
                        "\u001b[1;31mKeyboardInterrupt\u001b[0mTraceback (most recent call last)", 
                        "\u001b[1;32m/gpfs/global_fs01/sym_shared/YPProdSpark/user/s940-fbcc213783342d-a0c48b40f6b0/notebook/work/tf-tutorial/tensorflow_lyrics_bot/main.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     26\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"__main__\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 28\u001b[1;33m     \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m", 
                        "\u001b[1;32m/gpfs/fs01/user/s940-fbcc213783342d-a0c48b40f6b0/.local/lib/python3.5/site-packages/tensorflow/python/platform/app.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(main, argv)\u001b[0m\n\u001b[0;32m     42\u001b[0m   \u001b[1;31m# Call the main function, passing through any arguments\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     43\u001b[0m   \u001b[1;31m# to the final program.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 44\u001b[1;33m   \u001b[0m_sys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_sys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margv\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mflags_passthrough\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     45\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     46\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n", 
                        "\u001b[1;32m/gpfs/global_fs01/sym_shared/YPProdSpark/user/s940-fbcc213783342d-a0c48b40f6b0/notebook/work/tf-tutorial/tensorflow_lyrics_bot/main.py\u001b[0m in \u001b[0;36mmain\u001b[1;34m(_)\u001b[0m\n\u001b[0;32m     16\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"[args]: \"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmode\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'train'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 18\u001b[1;33m       \u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     19\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmode\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'test'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m       \u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n", 
                        "\u001b[1;32m/gpfs/global_fs01/sym_shared/YPProdSpark/user/s940-fbcc213783342d-a0c48b40f6b0/notebook/work/tf-tutorial/tensorflow_lyrics_bot/lib/train.py\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(args)\u001b[0m\n\u001b[0;32m     84\u001b[0m           \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     85\u001b[0m             _, step_loss, _ = model.step(sess, encoder_inputs, decoder_inputs,\n\u001b[1;32m---> 86\u001b[1;33m                                          target_weights, bucket_id, forward_only=False, force_dec_input=True)\n\u001b[0m\u001b[0;32m     87\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     88\u001b[0m           \u001b[0mstep_time\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mstart_time\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m/\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msteps_per_checkpoint\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n", 
                        "\u001b[1;32m/gpfs/global_fs01/sym_shared/YPProdSpark/user/s940-fbcc213783342d-a0c48b40f6b0/notebook/work/tf-tutorial/tensorflow_lyrics_bot/lib/seq2seq_model.py\u001b[0m in \u001b[0;36mstep\u001b[1;34m(self, session, encoder_inputs, decoder_inputs, target_weights, bucket_id, forward_only, force_dec_input, advantage)\u001b[0m\n\u001b[0;32m    290\u001b[0m         \u001b[0moutput_feed\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mbucket_id\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0ml\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    291\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 292\u001b[1;33m     \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msession\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput_feed\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_feed\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    293\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mforward_only\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    294\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0moutputs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m  \u001b[1;31m# Gradient norm, loss, no outputs.\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n", 
                        "\u001b[1;32m/gpfs/fs01/user/s940-fbcc213783342d-a0c48b40f6b0/.local/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    765\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    766\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 767\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    768\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    769\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n", 
                        "\u001b[1;32m/gpfs/fs01/user/s940-fbcc213783342d-a0c48b40f6b0/.local/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    963\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    964\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[1;32m--> 965\u001b[1;33m                              feed_dict_string, options, run_metadata)\n\u001b[0m\u001b[0;32m    966\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    967\u001b[0m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n", 
                        "\u001b[1;32m/gpfs/fs01/user/s940-fbcc213783342d-a0c48b40f6b0/.local/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[1;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1013\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1014\u001b[0m       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,\n\u001b[1;32m-> 1015\u001b[1;33m                            target_list, options, run_metadata)\n\u001b[0m\u001b[0;32m   1016\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1017\u001b[0m       return self._do_call(_prun_fn, self._session, handle, feed_dict,\n", 
                        "\u001b[1;32m/gpfs/fs01/user/s940-fbcc213783342d-a0c48b40f6b0/.local/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1020\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1021\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1022\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1023\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1024\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n", 
                        "\u001b[1;32m/gpfs/fs01/user/s940-fbcc213783342d-a0c48b40f6b0/.local/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[1;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[0;32m   1002\u001b[0m         return tf_session.TF_Run(session, options,\n\u001b[0;32m   1003\u001b[0m                                  \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1004\u001b[1;33m                                  status, run_metadata)\n\u001b[0m\u001b[0;32m   1005\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1006\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msession\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n", 
                        "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
                    ], 
                    "evalue": "", 
                    "ename": "KeyboardInterrupt", 
                    "output_type": "error"
                }
            ], 
            "execution_count": 33
        }, 
        {
            "cell_type": "code", 
            "source": "from io import BytesIO  \nimport requests  \nimport json  \nimport pandas as pd\nimport tarfile\nimport codecs\nimport gzip\n\n\ndef put_file(local_file_name):  \n    \"\"\"This functions returns a StringIO object containing\n    the file content from Bluemix Object Storage V3.\"\"\"\n\n    my_data = gzip.open(local_file_name)\n\n    #my_data = open(local_file_name,'r')\n    #my_data = codecs.open(local_file_name, \"r\",encoding='utf-8', errors='ignore')\n    #f = open(local_file_name,'r')\n    #my_data = f.read()\n    \n    url1 = ''.join(['https://identity.open.softlayer.com', '/v3/auth/tokens'])\n    data = {'auth': {'identity': {'methods': ['password'],\n            'password': {'user': {'name': 'member_fb8e5938c53df784b12cd53aadbd3c904a812670','domain': {'id': 'a6ca2738c3ca49b3be81f963f7c0c794'},\n            'password': 'D-lp89724?nTlj^g'}}}}}\n    headers1 = {'Content-Type': 'application/json'}\n    resp1 = requests.post(url=url1, data=json.dumps(data), headers=headers1)\n    resp1_body = resp1.json()\n    for e1 in resp1_body['token']['catalog']:\n        if(e1['type']=='object-store'):\n            for e2 in e1['endpoints']:\n                        if(e2['interface']=='public'and e2['region']=='dallas'):\n                            url2 = ''.join([e2['url'],'/', 'Chatbotloadfile', '/', local_file_name])\n    s_subject_token = resp1.headers['x-subject-token']\n    headers2 = {'X-Auth-Token': s_subject_token, 'Accept-Encoding': None}\n    resp2 = requests.put(url=url2, headers=headers2, data = my_data )\n    print(resp2)", 
            "metadata": {
                "collapsed": true
            }, 
            "outputs": [], 
            "execution_count": 34
        }, 
        {
            "cell_type": "code", 
            "source": "!tar -zcvf subtitle.tar.gz works/subtitle/", 
            "metadata": {}, 
            "outputs": [
                {
                    "output_type": "stream", 
                    "text": "works/subtitle/\nworks/subtitle/results/\nworks/subtitle/nn_models/\nworks/subtitle/nn_models/model.ckpt-500.meta\nworks/subtitle/nn_models/model.ckpt-500.index\nworks/subtitle/nn_models/checkpoint\nworks/subtitle/nn_models/model.ckpt-500.data-00000-of-00001\nworks/subtitle/data/\nworks/subtitle/data/chat_test.in\nworks/subtitle/data/train/\nworks/subtitle/data/train/chat.txt.gz\nworks/subtitle/data/chat.in\nworks/subtitle/data/chat.ids150000.in\nworks/subtitle/data/test/\nworks/subtitle/data/test/test_set.txt\nworks/subtitle/data/vocab150000.in\nworks/subtitle/data/chat_test.ids150000.in\n", 
                    "name": "stdout"
                }
            ], 
            "execution_count": 36
        }, 
        {
            "cell_type": "code", 
            "source": "put_file('subtitle.tar.gz')", 
            "metadata": {
                "collapsed": true
            }, 
            "outputs": [], 
            "execution_count": null
        }, 
        {
            "cell_type": "code", 
            "source": "", 
            "metadata": {
                "collapsed": true
            }, 
            "outputs": [], 
            "execution_count": null
        }
    ], 
    "nbformat": 4, 
    "metadata": {
        "kernelspec": {
            "language": "python", 
            "name": "python3-spark21", 
            "display_name": "Python 3.5 (Experimental) with Spark 2.1"
        }, 
        "language_info": {
            "file_extension": ".py", 
            "codemirror_mode": {
                "version": 3, 
                "name": "ipython"
            }, 
            "pygments_lexer": "ipython3", 
            "version": "3.5.2", 
            "nbconvert_exporter": "python", 
            "mimetype": "text/x-python", 
            "name": "python"
        }
    }, 
    "nbformat_minor": 1
}